install.packages("updateR")
install.packages("installr")
installr::updateR()
library(reshape)
install.packages("dplyr")
install.packages("reshape")
install.packages("ez")
install.packages("lrd")
install.packages("vectsects")
install.packages("Vectsects")
install.packages("VectSects")
install.packages("psych")
install.packages("Hmisc")
install.packages("PsychReport")
install.packages("psychReport")
install.packages("caret")
2406*.10
12*9
14*19
108/266
19/12
12/12
14/9
12*1.5
9*1/5
9*1.5
13.5/9
18/12
15-13.5
108/266
13.5*18
108/243
13.5/9
18/12
getwd()
library(lrd)
write.csv(lrd::cued_recall_manuscript, row.names = F)
write.csv(lrd::cued_recall_manuscript, file = "lrd_test.csv", row.names = F)
table(lrd::cued_recall_manuscript$Trial_num)
View(subst(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 1))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 1))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 2))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 3))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 20))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 18))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 17))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 19))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 10))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 15))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 16))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 14))
View(subset(lrd::cued_recall_manuscript, lrd::cued_recall_manuscript$Trial_num == 13))
write.csv(lrd::answer_key_free2, file = "free_key.csv", row.names = F)
write.csv(lrd::free_data, file = "free_data.csv", row.names = F)
write.csv(lrd::multi_data, file = "free_m.csv", row.names = F)
write.csv(lrd:multi_answers, file = "key_m.csv", row.names = F)
write.csv(lrd::multi_answers, file = "key_m.csv", row.names = F)
multi = lrd::multi_answers
View(multi)
library(reshape)
View(multi)
multi2 = melt(multi)
View(multi2)
multi2 = melt(multi, measure.vars = c("List1", "List2", "List3", "List4", "List5", "List6"))
View(multi2)
colnames(mult2)[1:2] = c("List_Type", "Key")
colnames(multi2)[1:2] = c("List_Type", "Key")
multi2$Key = tolower(multi2$Key)
write.csv(multi2, file = "free_M_key.csv", row.names = F)
library(scales)
cite(scales)
citation(scales)
citation("scales")
install.packages("updateR")
install.packages("installr")
installr::updater()
library(lrd)
citation(package = "lrd")
371+400+156+30+65+200+400+75
3600-1697-300-1000
library(lrd)
write.csv(lrd::answer_key_free2, file = "test_key.csv", row.names = F)
lrd::free_data
?arrange_data
arrange_data(lrd::free_data, responses = Response, sep = " ",
Username)
arrange_data(lrd::free_data, responses = Response, sep = " ",
"Username")
arrange_data(lrd::free_data, responses = "Response", sep = " ",
"Username")
lrd::free_data
lrd::free_data
write.csv(arrange_data(lrd::free_data, responses = "Response", sep = " ",
"Username"), file = "test.csv", row.names = F)
answer_key_free2
wide_data
answer_key_free
write.csv(lrd::answer_key_free, file = "test_key.csv", row.names = F)
write.csv(arrange_data(lrd::wide_data, responses = "Response", sep = " ",
"Username"), file = "test.csv", row.names = F)
write.csv(arrange_data(lrd::wide_data, responses = "Response", sep = ",",
"Username"), file = "test.csv", row.names = F)
key = lrd::answer_key_free
all_lags <- sort(c((1:(nrow(key) - 1)) * -1, 1:(nrow(key) - 1)))
merge_lags <- data.frame(Sub.ID = rep(unique(DF$Sub.ID), each = length(all_lags)),
participant_lags = rep(all_lags, length(unique(DF$Sub.ID))))
View(all_lags)
####Set up####
##read in the data
dat = read.csv("Data/JOL_data.csv")
##Load libraries
library(ez)
library(psychReport)
library(reshape)
##turn off scientific notation
options(scipen = 999)
#check ethnicities
table(dat$participant.ethnicity) / 40
(48 * 20) + (15 * 26)
x = c(1,7,9,12,15,2,8,3,2)
mean(x)
sd(x)
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/ED-JOLs/4 Analyses")
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/ED-JOLs/4 Analyses/Ex 1A")
####Set up####
##read in data
dat = read.csv("Ex 1A scored.csv")
##turn off scientific notation
options(scipen = 999)
##load libraries
library(ez)
library(reshape)
library(psychReport)
View(dat)
####format the dataset
##drop the pilot data
dat = subset(dat,
dat$Source != "MSU")
View(dat)
##get groups
read = subset(dat,
dat$encoding == "read")
term = subset(dat,
dat$encoding == "term")
glob = subset(dat,
dat$encoding == "glob")
glob = subset(dat,
dat$encoding == "global")
##get starting ns
length(unique(dat$ID))
length(unique(read$ID))
length(unique(term$ID))
length(unique(glob$ID))
##Convert Ys and Ns to 1s and 0s
dat$Correct.[dat$Correct. == "Y"] = "1"
dat$Correct.[dat$Correct. == "N"] = "0"
dat$Correct. == as.numeric(dat$Correct.)
dat$Correct. = as.numeric(dat$Correct.)
colnames(dat)[8] = "scored"
##get groups
read = subset(dat,
dat$encoding == "read")
term = subset(dat,
dat$encoding == "term")
glob = subset(dat,
dat$encoding == "global")
##get starting ns
length(unique(dat$ID)) #106 (overall)
length(unique(read$ID)) #35 -- read
length(unique(term$ID)) #34 -- term (item)
length(unique(glob$ID)) #37 -- global
##get overall descriptives
tapply(dat$scored, dat$encoding, mean)
View(glob)
####Data Cleaning####
##remove < 5%; > 95% (will also check JOL data to ensure that they stayed on task)
dat2 = cast(dat, ID ~ encoding, mean)
View(dat2)
#one term and global at 0%
dat = subset(dat, dat$ID != "3023" | dat$ID != "2014")
#one term and global at 0%
dat = subset(dat, dat$ID != "3023" & dat$ID != "2014")
#re-run descriptives
tapply(dat$scored, dat$encoding, mean)
View(dat)
####Run the ANOVA####
#one-way, between subjects
model1 = ezANOVA(dat,
dv = scored,
between = encoding,
wid = ID,
type = 3,
detailed = T)
model1
####Set up####
##read in data
dat = read.csv("Ex 1A scored.csv")
##turn off scientific notation
options(scipen = 999)
##load libraries
library(ez)
library(reshape)
library(psychReport)
####format the dataset
##drop the pilot data
##Convert Ys and Ns to 1s and 0s
dat$Correct.[dat$Correct. == "Y"] = "1"
dat$Correct.[dat$Correct. == "N"] = "0"
dat$Correct. = as.numeric(dat$Correct.)
colnames(dat)[8] = "scored"
##get groups
read = subset(dat,
dat$encoding == "read")
term = subset(dat,
dat$encoding == "term")
glob = subset(dat,
dat$encoding == "global")
##get starting ns
length(unique(dat$ID)) #106 (overall)
length(unique(read$ID)) #35 -- read (34)
length(unique(term$ID)) #34 -- term (item)
length(unique(glob$ID)) #37 -- global (36)
##get overall descriptives
tapply(dat$scored, dat$encoding, mean) #looks like no reactivity; possible negative reactivty on item-level JOLs
####Data Cleaning####
##remove < 5%; > 95% (will also check JOL data to ensure that they stayed on task)
dat2 = cast(dat, ID ~ encoding, mean)
#one term and global at 0%
dat = subset(dat, dat$ID != "3023" & dat$ID != "2014")
#re-run descriptives
tapply(dat$scored, dat$encoding, mean)
####Run the ANOVA####
#one-way, between subjects
model1 = ezANOVA(dat,
dv = scored,
between = encoding,
wid = ID,
type = 3,
detailed = T)
model1 #non-significant
length(unique(read$ID)) #35 -- read (34)
length(unique(term$ID)) #34 -- term (item)
length(unique(glob$ID)) #37 -- global (36)
####Set up####
##read in data
dat = read.csv("Ex 1A scored.csv")
##turn off scientific notation
options(scipen = 999)
##load libraries
library(ez)
library(reshape)
library(psychReport)
##Convert Ys and Ns to 1s and 0s
dat$Correct.[dat$Correct. == "Y"] = "1"
dat$Correct.[dat$Correct. == "N"] = "0"
dat$Correct. = as.numeric(dat$Correct.)
colnames(dat)[8] = "scored"
##get groups
read = subset(dat,
dat$encoding == "read")
term = subset(dat,
dat$encoding == "term")
glob = subset(dat,
dat$encoding == "global")
##get starting ns
length(unique(dat$ID)) #106 (overall)
length(unique(read$ID)) #35 -- read (34)
View(dat)
##fix subject IDs
dat.MSU = subset(dat,
dat$Source == "MSU")
dat.P = subset(dat,
dat$Source != "MSU")
View(dat)
dat.MSU$ID = dat.MSU$ID + 10000
dat = rbind(dat.MSU, dat.p)
dat = rbind(dat.MSU, dat.P)
##get groups
read = subset(dat,
dat$encoding == "read")
term = subset(dat,
dat$encoding == "term")
glob = subset(dat,
dat$encoding == "global")
##get starting ns
length(unique(dat$ID)) #106 (overall)
length(unique(read$ID)) #35 -- read (34)
length(unique(term$ID)) #34 -- term (item) | w/msu ()
##get starting ns
length(unique(dat$ID)) #106 (overall)      | w/msu
length(unique(glob$ID)) #37 -- global (36) |
##get overall descriptives
tapply(dat$scored, dat$encoding, mean) #looks like no reactivity; possible negative reactivty on item-level JOLs
####Data Cleaning####
##remove < 5%; > 95% (will also check JOL data to ensure that they stayed on task)
dat2 = cast(dat, ID ~ encoding, mean)
View(dat2)
#one term and global at 0%
dat = subset(dat, dat$ID != "3023" & dat$ID != "2014")
#re-run descriptives
tapply(dat$scored, dat$encoding, mean)
####Run the ANOVA####
#one-way, between subjects
model1 = ezANOVA(dat,
dv = scored,
between = encoding,
wid = ID,
type = 3,
detailed = T)
model1 #non-significant
####Set up####
##read in data
dat = read.csv("Ex 1A scored.csv")
View(dat)
##turn off scientific notation
options(scipen = 999)
##load libraries
library(ez)
library(reshape)
library(psychReport)
##Convert Ys and Ns to 1s and 0s
dat$Correct.[dat$Correct. == "Y"] = "1"
dat$Correct.[dat$Correct. == "N"] = "0"
dat$Correct. = as.numeric(dat$Correct.)
colnames(dat)[8] = "scored"
##fix subject IDs
dat.MSU = subset(dat,
dat$Source == "MSU")
dat.P = subset(dat,
dat$Source != "MSU")
dat.MSU$ID = dat.MSU$ID + 10000
dat = rbind(dat.MSU, dat.P)
##get groups
read = subset(dat,
dat$encoding == "read")
term = subset(dat,
dat$encoding == "term")
glob = subset(dat,
dat$encoding == "global")
##get starting ns
length(unique(dat$ID)) #106 (overall)      | w/msu (113)
length(unique(read$ID)) #35 -- read (34)   | w/msu (37)
length(unique(term$ID)) #34 -- term (item) | w/msu (36)
length(unique(glob$ID)) #37 -- global (36) | w/msu (40)
##get overall descriptives
tapply(dat$scored, dat$encoding, mean) #looks like no reactivity; possible negative reactivty on item-level JOLs
####Data Cleaning####
##remove < 5%; > 95% (will also check JOL data to ensure that they stayed on task)
dat2 = cast(dat, ID ~ encoding, mean)
#one term and global at 0%
dat = subset(dat, dat$ID != "3023" & dat$ID != "2014")
####Run the ANOVA####
#one-way, between subjects
model1 = ezANOVA(dat,
dv = scored,
between = encoding,
wid = ID,
type = 3,
detailed = T)
model1 #non-significant
#re-run descriptives
tapply(dat$scored, dat$encoding, mean)
setwd("C:/Users/nickm/OneDrive/Documents")
n = read.csv(ns.csv)
n = read.csv("ns.csv")
View(n)
length(unique(n$Username))
MX = 54.20
MY = 58.28
MDIFF = 4.08
SDX = 11.89
SDY = 9.95
SDDIFF = 5.41
RXX = .503
RYY = .236
rXY = .892
(SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY)
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY)) / (SDX^2 + SDY^2) - (2 * rxy *SDX * SDY)
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY)) / (SDX^2 + SDY^2) - (2 * rxy *SDX * SDY)
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY)) / (SDX^2 + SDY^2) - (2 * Rxy *SDX * SDY)
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY)) / (SDX^2 + SDY^2) - (2 * rXY *SDX * SDY)
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY))
(SDX^2 + SDY^2) - (2 * rXY *SDX * SDY)
SDX^2
SDY^2
2 * rXY * SDX * SDY
2 * rXY *SDX * SDY
(SDX^2 + SDY^2)
(SDX^2 + SDY^2 - 2 * rXY *SDX * SDY)
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY))
((SDX^2 * RXX) + (SDY^2 * RYY) - (2 * rXY * SDX * SDY)) / (SDX^2 + SDY^2 - 2 * rXY *SDX * SDY)
setwd("~/GitHub/Mediated-Reactivity-2/2 Output/Ex 2A/MSU")
setwd("~/GitHub/Mediated-Reactivity-2/2 Output/Ex 2A/MSU")
