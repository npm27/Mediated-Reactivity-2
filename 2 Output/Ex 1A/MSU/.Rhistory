temp = t.test(r.ph.b2$W, r.ph.b2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
##recog
temp = t.test(r.ph.w2$W, r.ph.w2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
table(combined$participant.ethnicity) / 80 #38 white participants, 21 black participants
####Set up####
##read in the data
dat = rbind(read.csv("Data/MSU/JOL_data.csv"), read.csv("Data/EC/JOL_data_EC.csv"), read.csv("Data/JSU/JOL_data_JSU.csv")) #will also want to cbind in the JSU data when its available
#dat = read.csv("Data/MSU/JOL_data.csv")
##load libraries
library(ez)
library(reshape)
library(psychReport)
##turn off scientific notation
options(scipen = 999)
##drop all participants except black/white individuals
table(dat$participant.ethnicity) / 40
dat2 = subset(dat,
dat$participant.ethnicity == "White" | dat$participant.ethnicity == "Black" )
##get recog on same scale as JOLs
dat2$scored = dat2$scored * 100
##get data in long form
#fix column names
colnames(dat2)[3] = "JOL"
colnames(dat2)[6] = "recog"
#remove JOLs > 100
dat2$JOL[dat2$JOL > 100] = NA
#wide -> long
dat2.long = melt(dat2,
id = c("Username", "participant.ethnicity", "Target_Ethnicity", "Target_Gender"))
#and fix column names one more time
colnames(dat2.long)[5:6] = c("Task", "Score")
##White participants
white = subset(dat2.long,
dat2.long$participant.ethnicity == "White")
black = subset(dat2.long,
dat2.long$participant.ethnicity == "Black")
##and check for outliers
#any participants who are just making JOLs of all 100?
##white
white.wide = cast(subset(white,
white$Task == "recog"),
Username ~ Target_Ethnicity, mean)
white.wide$diff = (white.wide$B - white.wide$W)
##black
black.wide = cast(subset(black,
black$Task == "recog"),
Username ~ Target_Ethnicity, mean)
black.wide$diff = (black.wide$W - black.wide$B)
##drop outliers here
white = subset(white,
white$Username != "AlyssaMarsh")
white = subset(white,
white$Username != "KadrianStines")
white = subset(white,
white$Username != "AutumnAllen")
white = subset(white,
white$Username != "CalebLane")
##Recombine for ANOVAs
#2(participant ethnicity) x 2(target race) x 2(task type)
#or do separate anovas for each racial group? (kinda leaning towards this for parsimony...)
combined = rbind(white, black)
table(combined$participant.ethnicity) / 80 #38 white participants, 22 black participants
#general patterns
tapply(black$Score, list(black$Task, black$Target_Ethnicity), mean, na.rm = T)
tapply(white$Score, list(white$Task, white$Target_Ethnicity), mean, na.rm = T)
combined2 = na.omit(combined)
#full model
model1 = ezANOVA(combined2,
dv = Score,
between = participant.ethnicity,
within = .(Target_Ethnicity, Task),
wid = Username,
type = 3,
detailed = T)
model1
##JOLs
com.JOLs = subset(combined2,
combined2$Task == "JOL")
com.recog = subset(combined2,
combined2$Task == "recog")
model2 = ezANOVA(com.JOLs,
dv = Score,
between = participant.ethnicity,
within = Target_Ethnicity,
wid = Username,
type = 3,
detailed = T)
model2
##recog
model3 = ezANOVA(com.recog,
dv = Score,
between = participant.ethnicity,
within = Target_Ethnicity,
wid = Username,
type = 3,
detailed = T)
model3
####Post Hocs####
##set up
r.ph.w = subset(com.recog,
com.recog$participant.ethnicity == "White")
r.ph.b = subset(com.recog,
com.recog$participant.ethnicity == "Black")
r.ph.w2 = cast(r.ph.w, Username ~ Target_Ethnicity, mean)
r.ph.b2 = cast(r.ph.b, Username ~ Target_Ethnicity, mean)
##recog
temp = t.test(r.ph.w2$W, r.ph.w2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #Significant!
temp = t.test(r.ph.b2$W, r.ph.b2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92 #marginal ns (super small sample though)
table(combined$participant.ethnicity) / 80 #38 white participants, 22 black participants
#general patterns
tapply(black$Score, list(black$Task, black$Target_Ethnicity), mean, na.rm = T)
tapply(white$Score, list(white$Task, white$Target_Ethnicity), mean, na.rm = T)
##recog
temp = t.test(r.ph.w2$W, r.ph.w2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
temp = t.test(r.ph.b2$W, r.ph.b2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
##recog
temp = t.test(r.ph.w2$W, r.ph.w2$B, paired = T, p.adjust.methods = "bonferroni", var.equal = T)
temp
View(white.wide)
View(black.wide)
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/Read")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 13:14)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 13:14)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Response.Response[JOL$Response.Response == 	"beyonc�"] = ""
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #11
length(unique(Study$Username)) #12
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/Read")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 13:14)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 13:14)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Response.Response[JOL$Response.Response == 	"beyonc�"] = ""
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #11
length(unique(Study$Username)) #12
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/Read")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 13:14)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 13:14)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Response.Response[JOL$Response.Response == 	"beyonc�"] = ""
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #11
length(unique(Study$Username)) #12
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 1A/MSU/Read")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 13:14)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 13:14)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Response.Response[JOL$Response.Response == 	"beyonc�"] = ""
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #11
length(unique(Study$Username)) #12
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11)], file = "JOL_pre_scored.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10)], file = "Study_pre_scored.csv", row.names = F)
