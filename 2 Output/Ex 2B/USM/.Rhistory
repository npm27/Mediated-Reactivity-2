Read = subset(Read,
id != "w10175528_CLJ" & id != "M20343281ega" & id != "M20223504BG" & id != "M20340785CH" &
id != "w10185331" & id != "M20348084_HJH")
#CLJ, BG < 5%
#ega > 95%
##put everything together
combined = rbind(JOL[ , -7], Read)
combined = combined[ , c(1, 3:5, 6, 2)]
#make recall a percent
combined$Scored = combined$Scored * 100
####Descriptives####
tapply(combined$Scored, list(combined$Encoding_Group, combined$Direction), mean) #reactivity patterns (recall)
tapply(JOL$JOL, JOL$Direction, mean, na.rm = T)
##test JOLs
JOL2 = na.omit(JOL)
mod.jol = ezANOVA(JOL2,
wid = id,
dv = JOL,
between = Direction,
type = 3,
detailed = T)
mod.jol #overall is sig
JOL.wide3 = cast(JOL2, id ~ Direction, value = "JOL", mean, na.rm = T)
#F vs M
temp = t.test(JOL.wide3$F, JOL.wide3$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(JOL.wide3$F, JOL.wide3$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#M vs U
temp = t.test(JOL.wide3$M, JOL.wide3$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #marginal
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
####Run the ANOVAs####
model1 = ezANOVA(combined,
wid = id,
dv = Scored,
between = Encoding_Group,
within = Direction,
type = 3,
detailed = T)
model1
model1$ANOVA$MSE = model1$ANOVA$SSd/model1$ANOVA$DFd
model1$ANOVA$MSE
aovEffectSize(model1, effectSize = "pes")
####comparisons####
tapply(combined$Scored, combined$Encoding_Group, mean) #main effect encoding
tapply(combined$Scored, combined$Direction, mean) #main effect direction
tapply(combined$Scored, list(combined$Encoding_Group, combined$Direction), mean, na.rm = T) #Interaction
####Post-Hocs####
###break down direction main effect
combined.direction = cast(combined, id ~ Direction, mean)
#F vs M
temp = t.test(combined.direction$F, combined.direction$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(combined.direction$F, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#U vs M
temp = t.test(combined.direction$M, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
##get sds for d
mean(combined.direction$F); sd(combined.direction$F)
mean(combined.direction$M); sd(combined.direction$M)
mean(combined.direction$U); sd(combined.direction$U)
#Not surprisingly, everything is sig!
###Interaction
jol3 = subset(combined, combined$Encoding_Group == "JOL")
read3 = subset(combined, combined$Encoding_Group == "Read")
jol.ph = cast(jol3, id ~ Direction, mean)
read.ph = cast(read3, id ~ Direction, mean)
(apply(jol.ph[ , -1], 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph[ , -1], 2, sd) / sqrt(nrow(read.ph))) * 1.96
nrow(jol.ph)
nrow(read.ph)
mean(jol.ph$F); mean(jol.ph$M)
mean(read.ph$F); mean(read.ph$M)
##forward
temp = t.test(jol.ph$F, read.ph$F, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
sd(jol.ph$F); sd(read.ph$F) #d = 0.68
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
pbic1 = jol.ph[ , c(1,3)]
pbic2 = read.ph[ , c(1,3)]
pbic1$group = rep("jol")
pbic2$group = rep("read")
pbic3 = rbind(pbic1, pbic2)
ezANOVA(pbic3,
dv = M,
between = group,
wid = id,
type = 3,
detailed = T)
#unrelated
temp = t.test(jol.ph$U, read.ph$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
pbic1 = jol.ph[ , c(1,4)]
pbic2 = read.ph[ , c(1,4)]
pbic1$group = rep("jol")
pbic2$group = rep("read")
pbic3 = rbind(pbic1, pbic2)
ezANOVA(pbic3,
dv = U,
between = group,
wid = id,
type = 3,
detailed = T)
#post cleaning group sizes
length(unique(jol.ph$id)) #64
length(unique(read.ph$id)) #62
##Get CIs for table
(apply(jol.ph, 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph, 2, sd) / sqrt(nrow(read.ph))) * 1.96
tapply(combined$Scored, list(combined$Encoding_Group, combined$Direction), mean, na.rm = T) #Interaction
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
####set up####
##read in data
JOL = rbind(read.csv("MSU/JOL Scored MSU.csv"), read.csv("USM/JOL Scored USM.csv"))
Read = rbind(read.csv("MSU/Read Scored MSU.csv"), read.csv("USM/Read Scored USM.csv"))
table(JOL$source) / 90 + table(Read$source) / 90
##load libraries
library(reshape)
library(ez)
library(psychReport)
options(scipen = 999)
##set up the dataframe
JOL = JOL[ , -c(2:4, 6, 8, 11, 14)]
Read = Read[ , -c(2:4, 6, 8, 11, 13)]
colnames(JOL)[3] = "Encoding_Group"
colnames(JOL)[4] = "Block"
colnames(JOL)[5] = "Direction"
colnames(JOL)[7] = "JOL"
colnames(Read)[3] = "Encoding_Group"
colnames(Read)[4] = "Block"
colnames(Read)[5] = "Direction"
#fix out of range JOLs
JOL$JOL[JOL$JOL > 100] = NA
##check for outliers
#recall
JOL.wide = cast(JOL, id ~ Direction, value = "Scored", mean)
Read.wide = cast(Read, id ~ Direction, value = "Scored", mean)
##anyone not do the JOL task?
JOL.wide2 = cast(JOL, id ~ Direction, value = "JOL", mean, na.rm = T)
#drop them
JOL = subset(JOL,
id != "w10191338" & id != "w10184950DT" & id != "w10182464" & id != "w10175813" & id != "M20347389" &
id != "w10197529maa" & id != "M20346828Ce")
Read = subset(Read,
id != "w10175528_CLJ" & id != "M20343281ega" & id != "M20223504BG" & id != "M20340785CH" &
id != "w10185331" & id != "M20348084_HJH")
##put everything together
combined = rbind(JOL[ , -7], Read)
combined = combined[ , c(1, 3:5, 6, 2)]
#make recall a percent
combined$Scored = combined$Scored * 100
####Descriptives####
tapply(combined$Scored, list(combined$Encoding_Group, combined$Direction), mean) #reactivity patterns (recall)
tapply(JOL$JOL, JOL$Direction, mean, na.rm = T)
##test JOLs
JOL2 = na.omit(JOL)
mod.jol = ezANOVA(JOL2,
wid = id,
dv = JOL,
between = Direction,
type = 3,
detailed = T)
mod.jol #overall is sig
JOL.wide3 = cast(JOL2, id ~ Direction, value = "JOL", mean, na.rm = T)
#F vs M
temp = t.test(JOL.wide3$F, JOL.wide3$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(JOL.wide3$F, JOL.wide3$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#M vs U
temp = t.test(JOL.wide3$M, JOL.wide3$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #marginal
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
####Run the ANOVAs####
model1 = ezANOVA(combined,
wid = id,
dv = Scored,
between = Encoding_Group,
within = Direction,
type = 3,
detailed = T)
model1
model1$ANOVA$MSE = model1$ANOVA$SSd/model1$ANOVA$DFd
model1$ANOVA$MSE
aovEffectSize(model1, effectSize = "pes")
####comparisons####
tapply(combined$Scored, combined$Encoding_Group, mean) #main effect encoding
tapply(combined$Scored, combined$Direction, mean) #main effect direction
tapply(combined$Scored, list(combined$Encoding_Group, combined$Direction), mean, na.rm = T) #Interaction
####Post-Hocs####
###break down direction main effect
combined.direction = cast(combined, id ~ Direction, mean)
#F vs M
temp = t.test(combined.direction$F, combined.direction$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#F vs U
temp = t.test(combined.direction$F, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
#U vs M
temp = t.test(combined.direction$M, combined.direction$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
##get sds for d
mean(combined.direction$F); sd(combined.direction$F)
mean(combined.direction$M); sd(combined.direction$M)
mean(combined.direction$U); sd(combined.direction$U)
#Not surprisingly, everything is sig!
###Interaction
jol3 = subset(combined, combined$Encoding_Group == "JOL")
read3 = subset(combined, combined$Encoding_Group == "Read")
jol.ph = cast(jol3, id ~ Direction, mean)
read.ph = cast(read3, id ~ Direction, mean)
(apply(jol.ph[ , -1], 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph[ , -1], 2, sd) / sqrt(nrow(read.ph))) * 1.96
nrow(jol.ph)
nrow(read.ph)
mean(jol.ph$F); mean(jol.ph$M)
mean(read.ph$F); mean(read.ph$M)
##forward
temp = t.test(jol.ph$F, read.ph$F, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic #sig!
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
sd(jol.ph$F); sd(read.ph$F) #d = 0.68
##mediated
temp = t.test(jol.ph$M, read.ph$M, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
pbic1 = jol.ph[ , c(1,3)]
pbic2 = read.ph[ , c(1,3)]
pbic1$group = rep("jol")
pbic2$group = rep("read")
pbic3 = rbind(pbic1, pbic2)
ezANOVA(pbic3,
dv = M,
between = group,
wid = id,
type = 3,
detailed = T)
#unrelated
temp = t.test(jol.ph$U, read.ph$U, paired = F, p.adjust.methods = "bonferroni", var.equal = T)
temp
round(temp$p.value, 3)
temp$statistic
(temp$conf.int[2] - temp$conf.int[1]) / 3.92
pbic1 = jol.ph[ , c(1,4)]
pbic2 = read.ph[ , c(1,4)]
pbic1$group = rep("jol")
pbic2$group = rep("read")
pbic3 = rbind(pbic1, pbic2)
ezANOVA(pbic3,
dv = U,
between = group,
wid = id,
type = 3,
detailed = T)
#post cleaning group sizes
length(unique(jol.ph$id)) #64
length(unique(read.ph$id)) #62
##Get CIs for table
(apply(jol.ph, 2, sd) / sqrt(nrow(jol.ph))) * 1.96
(apply(read.ph, 2, sd) / sqrt(nrow(read.ph))) * 1.96
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 2B/MSU/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 2B/MSU/Study")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 14, 17)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 14, 16)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Response.Response[JOL$Response.Response == 	"beyonc�"] = ""
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #40
length(unique(Study$Username)) #39
#add source
JOL$source = rep("MSU")
Study$source = rep("MSU")
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11, 13)], file = "JOL_pre_scored_msu.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10, 12)], file = "Study_pre_scored_msu.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11, 13)], file = "JOL_pre_scored_msu.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10, 12)], file = "Study_pre_scored_msu.csv", row.names = F)
####This script will be used to read in everything and set EX 2data up for processing####
##Start by gathering all of the data
#JOLs and frequency
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 2B/USM/JOL")
files = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat$Username))
#read
setwd("C:/Users/nickm/OneDrive/Documents/GitHub/Mediated-Reactivity-2/2 Output/Ex 2B/USM/Study")
files2 = list.files(pattern = "*.csv")
#Put them in one dataframe. First apply read.csv, then rbind
dat2 = do.call(rbind, lapply(files2, function(x) read.csv(x, stringsAsFactors = FALSE)))
#get the number of participants
length(unique(dat2$Username))
#Now move back to the original folder
#This is where I'll store the combined final output for scoring
setwd('..')
####Clean up the data files####
##Drop unused columns
dat = dat[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:32, 34)]
dat2 = dat2[ , -c(2:4, 6:7, 9:10, 12, 20:23, 27:33)]
#Next, remove buffer trials
dat = subset(dat,
dat$Stimuli.Stimuli.Notes != "Buffer")
dat2 = subset(dat2,
dat2$Stimuli.Stimuli.Notes != "Buffer")
#Now remove instruction trials
dat = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "Instruct")
#Now remove filler task
dat = subset(dat,
dat$Procedure.Trial.Type != "FreeRecall")
dat2 = subset(dat2,
dat2$Procedure.Trial.Type != "FreeRecall")
####Set the data up for scoring####
#Start by subsetting out the recall and JOL data for each dataset
dat.JOL = subset(dat,
dat$Procedure.Trial.Type == "JOL")
dat.Recall = subset(dat,
dat$Procedure.Trial.Type == "Test")
#get JOLs and Recall in the same order
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Cue), ]
dat.JOL = dat.JOL[order(dat.JOL$Condition.Number), ]
dat.JOL = dat.JOL[order(dat.JOL$Stimuli.Shuffle), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Cue), ]
dat.Recall = dat.Recall[order(dat.Recall$Condition.Number), ]
dat.Recall = dat.Recall[order(dat.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat.R = dat.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
JOL = cbind(dat.JOL, dat.R)
JOL = JOL[ , -c(11, 14, 17)]
JOL = JOL[ , -c(9:10)]
JOL = JOL[ , -2]
##Now do the same for the study only condition
#Start by subsetting out the recall and study trials for each dataset
dat2.Study = subset(dat2,
dat2$Procedure.Trial.Type == "Study")
dat2.Recall = subset(dat2,
dat2$Procedure.Trial.Type == "Test")
#get Study and Recall in the same order
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Cue), ]
dat2.Study = dat2.Study[order(dat2.Study$Condition.Number), ]
dat2.Study = dat2.Study[order(dat2.Study$Stimuli.Shuffle), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Cue), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Condition.Number), ]
dat2.Recall = dat2.Recall[order(dat2.Recall$Stimuli.Shuffle), ]
#Okay, put it back together now
dat2.R = dat2.Recall[ , c(12:14)]
#Drop overlapping columns and clean things up
Study = cbind(dat2.Study, dat2.R)
Study = Study[ , -c(11, 14, 16)]
Study = Study[ , -c(9:10)]
Study = Study[ , -2]
####Score the recall data####
##Going to write everything to .csv and then use the old shiny app to score
#first lowercase everything
JOL$Response.Response[JOL$Response.Response == 	"beyonc�"] = ""
JOL$Stimuli.Cue = tolower(JOL$Stimuli.Cue)
JOL$Stimuli.Answer = tolower(JOL$Stimuli.Answer)
Study$Stimuli.Cue = tolower(Study$Stimuli.Cue)
Study$Stimuli.Answer = tolower(Study$Stimuli.Answer)
JOL$Response.Response = tolower(JOL$Response.Response)
Study$Response.Response = tolower(Study$Response.Response)
#now write to .csv for scoring
length(unique(JOL$Username)) #25
length(unique(Study$Username)) #26
#add source
JOL$source = rep("USM")
Study$source = rep("USM")
#write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11, 13)], file = "JOL_pre_scored_usm.csv", row.names = F)
#write.csv(Study[ , c(1, 11, 5, 2:4, 6:10, 12)], file = "Study_pre_scored_usm.csv", row.names = F)
write.csv(JOL[ , c(1, 12, 5, 2:4, 6:11, 13)], file = "JOL_pre_scored_usm.csv", row.names = F)
write.csv(Study[ , c(1, 11, 5, 2:4, 6:10, 12)], file = "Study_pre_scored_usm.csv", row.names = F)
